from pyspark.sql import SparkSession
from pyspark.sql.functions import year, expr, row_number
from pyspark.sql.window import Window

# Create SparkSession
spark = SparkSession.builder \
    .appName("Yearly Trend Analysis - Median") \
    .getOrCreate()

# Assuming trust_df is already created with the data

# Extract year from Period column
trust_df = trust_df.withColumn("Year", year("Period"))

# Calculate the median using window function
window_spec = Window.partitionBy("Year").orderBy("Type1_Departments_Major_A&E")
trust_df = trust_df.withColumn("Row_Num", row_number().over(window_spec))
trust_df.createOrReplaceTempView("trust_temp")

trend_analysis_df = spark.sql("""
    SELECT Year, 
           avg(Type1_Departments_Major_A&E) AS Median_Type1_Departments_Major_A&E
    FROM (
        SELECT Year,
               Type1_Departments_Major_A&E,
               Row_Num,
               count(*) AS Count
        FROM trust_temp
        GROUP BY Year, Type1_Departments_Major_A&E, Row_Num
        HAVING Row_Num >= Count / 2
        ORDER BY Year
    )
    GROUP BY Year
    ORDER BY Year
""")

# Show the trend analysis
trend_analysis_df.show()

# Stop SparkSession
spark.stop()




import pandas as pd
import matplotlib.pyplot as plt

# Convert Spark DataFrame to Pandas DataFrame
trend_analysis_pd = trend_analysis_df.toPandas()

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(trend_analysis_pd['Year'], trend_analysis_pd['Avg_Type1_Departments_Major_A&E'], marker='o', linestyle='-')
plt.title('Yearly Trend Analysis of Type1_Departments_Major_A&E')
plt.xlabel('Year')
plt.ylabel('Average Type1_Departments_Major_A&E')
plt.grid(True)
plt.xticks(trend_analysis_pd['Year'])
plt.tight_layout()
plt.show()
