from pyspark.sql.functions import year, month, quarter, count, expr, col

# Extract year, quarter, and month from the DateofLeaving column
merged_df_spark = merged_df_spark.withColumn("Year", year("DateofLeaving"))
merged_df_spark = merged_df_spark.withColumn("Quarter", quarter("DateofLeaving"))
merged_df_spark = merged_df_spark.withColumn("Month", month("DateofLeaving"))

# Group by year and quarter to calculate the number of employees who left
employees_left_per_quarter = merged_df_spark.groupBy("Year", "Quarter").agg(count("*").alias("EmployeesLeft")).orderBy("Year", "Quarter")

employees_left_per_quarter.display()

IllegalArgumentException: All week-based patterns are unsupported since Spark 3.0, detected: u, Please use the SQL function EXTRACT instead
