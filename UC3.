from pyspark.sql import SparkSession
from pyspark.sql.functions import year, expr

# Create SparkSession
spark = SparkSession.builder \
    .appName("Yearly Trend Analysis - Median") \
    .getOrCreate()

# Assuming trust_df is already created with the data

# Extract year from Period column
trust_df = trust_df.withColumn("Year", year("Period"))

# Group by Year and calculate median Type1_Departments_Major_A&E value
median_expr = expr("approxQuantile(Type1_Departments_Major_A&E, array(0.5), 10000)[0]")
trend_analysis_df = trust_df.groupBy("Year") \
    .agg(median_expr.alias("Median_Type1_Departments_Major_A&E"))

# Show the trend analysis
trend_analysis_df.orderBy("Year").show()

# Stop SparkSession
spark.stop()




import pandas as pd
import matplotlib.pyplot as plt

# Convert Spark DataFrame to Pandas DataFrame
trend_analysis_pd = trend_analysis_df.toPandas()

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(trend_analysis_pd['Year'], trend_analysis_pd['Avg_Type1_Departments_Major_A&E'], marker='o', linestyle='-')
plt.title('Yearly Trend Analysis of Type1_Departments_Major_A&E')
plt.xlabel('Year')
plt.ylabel('Average Type1_Departments_Major_A&E')
plt.grid(True)
plt.xticks(trend_analysis_pd['Year'])
plt.tight_layout()
plt.show()
